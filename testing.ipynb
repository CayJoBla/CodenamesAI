{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codenames.gym import CodenamesEnv\n",
    "\n",
    "env = CodenamesEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'board': [<Color.NEUTRAL: 2>,\n",
       "  <Color.BLUE: 1>,\n",
       "  <Color.BLUE: 1>,\n",
       "  <Color.BLUE: 1>,\n",
       "  <Color.NEUTRAL: 2>,\n",
       "  <Color.NEUTRAL: 2>,\n",
       "  <Color.RED: 0>,\n",
       "  <Color.RED: 0>,\n",
       "  <Color.BLUE: 1>,\n",
       "  <Color.ASSASSIN: 3>,\n",
       "  <Color.NEUTRAL: 2>,\n",
       "  <Color.RED: 0>,\n",
       "  <Color.RED: 0>,\n",
       "  <Color.RED: 0>,\n",
       "  <Color.BLUE: 1>,\n",
       "  <Color.NEUTRAL: 2>,\n",
       "  <Color.RED: 0>,\n",
       "  <Color.BLUE: 1>,\n",
       "  <Color.NEUTRAL: 2>,\n",
       "  <Color.BLUE: 1>,\n",
       "  <Color.RED: 0>,\n",
       "  <Color.RED: 0>,\n",
       "  <Color.NEUTRAL: 2>,\n",
       "  <Color.BLUE: 1>,\n",
       "  <Color.RED: 0>],\n",
       " 'words': ['BAR',\n",
       "  'AMAZON',\n",
       "  'WELL',\n",
       "  'CONCERT',\n",
       "  'SLIP',\n",
       "  'FILE',\n",
       "  'HORSE',\n",
       "  'MOLE',\n",
       "  'IRON',\n",
       "  'STAFF',\n",
       "  'BRUSH',\n",
       "  'AMBULANCE',\n",
       "  'PILOT',\n",
       "  'MEXICO',\n",
       "  'SUB',\n",
       "  'CENTER',\n",
       "  'RING',\n",
       "  'ROW',\n",
       "  'ANTARCTICA',\n",
       "  'THEATER',\n",
       "  'NUT',\n",
       "  'HOOK',\n",
       "  'LEMON',\n",
       "  'SCORPION',\n",
       "  'PUPIL'],\n",
       " 'guessed': [False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " 'turn': (<Team.RED: 0>, <Role.SPYMASTER: 0>)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-1B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n",
      "/home/yungdankblast/anaconda3/envs/codenames_ai/lib/python3.12/site-packages/trl/trainer/ppo_config.py:207: FutureWarning: `PPOConfig` is deprecated and will be removed in the future. Please use `PPOv2Config` with `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n",
      "/home/yungdankblast/anaconda3/envs/codenames_ai/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:193: FutureWarning: `PPOTrainer` is deprecated and will be removed in trl v0.12. Please use `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n",
      "/home/yungdankblast/anaconda3/envs/codenames_ai/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:273: UserWarning: No dataset is provided. Make sure to set config.batch_size to the correct value before training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from codenames.agents import Spymaster\n",
    "from codenames.constants import Team\n",
    "\n",
    "spymaster = Spymaster(team=Team.RED, model_name_or_path=\"meta-llama/Llama-3.2-1B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 09 Oct 2024\n",
      "\n",
      "You are the playing the game Codenames as the RED team's Spymaster.\n",
      "You are only allowed to give a single word hint followed by a number of words that correspond to the hint.\n",
      "Provide no context or additional information.\n",
      "Do not use a hint word that is already on the board.\n",
      "Provide your hint word and number separated by a space in the format \"HINT NUMBER\".<|eot_id|><|start_header_id|>context<|end_header_id|>\n",
      "\n",
      "RED Words:\n",
      "HORSE\n",
      "MOLE\n",
      "AMBULANCE\n",
      "PILOT\n",
      "MEXICO\n",
      "RING\n",
      "NUT\n",
      "HOOK\n",
      "PUPIL\n",
      "\n",
      "BLUE Words:\n",
      "AMAZON\n",
      "WELL\n",
      "CONCERT\n",
      "IRON\n",
      "SUB\n",
      "ROW\n",
      "THEATER\n",
      "SCORPION\n",
      "\n",
      "NEUTRAL Words:\n",
      "BAR\n",
      "SLIP\n",
      "FILE\n",
      "BRUSH\n",
      "CENTER\n",
      "ANTARCTICA\n",
      "LEMON\n",
      "\n",
      "ASSASSIN Words:\n",
      "STAFF<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Please provide a single word hint and a number of related words to the operatives on your team such that they can guess some of the RED Team's words without guessing any of the other team's words, neutral words, or the assassin word(s).<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(spymaster.get_prompt(env.state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: <|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "1. HINT NUMBER\n",
      "1. FILE\n",
      "2. RING\n",
      "3. SCORPION\n",
      "4. BRUSH\n",
      "5. PUPIL\n",
      "6. BAR<|eot_id|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "action = spymaster.get_action(env.state)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-1B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n",
      "/home/yungdankblast/anaconda3/envs/codenames_ai/lib/python3.12/site-packages/trl/trainer/ppo_config.py:207: FutureWarning: `PPOConfig` is deprecated and will be removed in the future. Please use `PPOv2Config` with `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n",
      "/home/yungdankblast/anaconda3/envs/codenames_ai/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:193: FutureWarning: `PPOTrainer` is deprecated and will be removed in trl v0.12. Please use `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n",
      "/home/yungdankblast/anaconda3/envs/codenames_ai/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:273: UserWarning: No dataset is provided. Make sure to set config.batch_size to the correct value before training.\n",
      "  warnings.warn(\n",
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'meta-llama/Llama-3.2-1B-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation State: {'board': [<Color.BLUE: 1>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.RED: 0>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.ASSASSIN: 3>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.BLUE: 1>], 'words': ['TRAIN', 'BOMB', 'SUIT', 'HORSESHOE', 'OIL', 'QUEEN', 'CALF', 'KANGAROO', 'MODEL', 'HIMALAYAS', 'SHADOW', 'SOLDIER', 'DINOSAUR', 'PRINCESS', 'OPERA', 'MOUNT', 'PITCH', 'FISH', 'BERMUDA', 'POUND', 'AMERICA', 'BUFFALO', 'TOKYO', 'LOCK', 'THIEF'], 'guessed': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'turn': (<Team.RED: 0>, <Role.SPYMASTER: 0>)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: <|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "1. HINT NUMBER\n",
      "BERMUDA 1\n",
      "1. HAWK 2\n",
      "2. BISON<|eot_id|>\n",
      "BERMUDA\n",
      "18\n",
      "BERMUDA\n",
      "False\n",
      "Spymaster's Action: BERMUDA 1\n",
      "Current Reward: -10\n",
      "Info: {'result': 'Invalid hint: BERMUDA 1. Game over.', 'error': 'ValueError: Hint word is currently on the board.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yungdankblast/anaconda3/envs/codenames_ai/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:1309: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1808.)\n",
      "  std_scores = data[\"scores\"].std()\n",
      "/home/yungdankblast/anaconda3/envs/codenames_ai/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:1336: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1808.)\n",
      "  stats[\"tokens/queries_len_std\"] = torch.std(query_lens).cpu().numpy().item()\n",
      "/home/yungdankblast/anaconda3/envs/codenames_ai/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:1339: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1808.)\n",
      "  stats[\"tokens/responses_len_std\"] = torch.std(response_lens).cpu().numpy().item()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation State: {'board': [<Color.RED: 0>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.RED: 0>, <Color.ASSASSIN: 3>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.NEUTRAL: 2>], 'words': ['PRINCESS', 'GOLD', 'TEMPLE', 'CENTER', 'POUND', 'HOSPITAL', 'POLICE', 'DINOSAUR', 'SCREEN', 'ROW', 'GLASS', 'MOUSE', 'BUCK', 'SCHOOL', 'LIGHT', 'HOLE', 'ROCK', 'FAIR', 'GLOVE', 'CYCLE', 'DANCE', 'CZECH', 'BALL', 'SHAKESPEARE', 'SPRING'], 'guessed': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'turn': (<Team.RED: 0>, <Role.SPYMASTER: 0>)}\n",
      "Response: <|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "1. RED Team words:\n",
      "- Color\n",
      "- Fruit\n",
      "- Animal sound\n",
      "- Italian dish\n",
      "- Asian dish\n",
      "- Hand gesture\n",
      "- Sport\n",
      "- Computer input\n",
      "- National flag\n",
      "- London landmark\n",
      "\n",
      "2. BLUE\n",
      "Spymaster's Action: \n",
      "Current Reward: -10\n",
      "Info: {'result': 'Invalid hint: . Game over.', 'error': 'ValueError: Hint must be a single word followed by a count.'}\n",
      "Observation State: {'board': [<Color.RED: 0>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.ASSASSIN: 3>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.RED: 0>], 'words': ['PANTS', 'ROW', 'SLUG', 'HOTEL', 'DATE', 'FALL', 'ANGEL', 'TRIANGLE', 'FOREST', 'CAST', 'TEMPLE', 'DROP', 'LAP', 'COURT', 'HOSPITAL', 'MILLIONAIRE', 'BERMUDA', 'CALF', 'CLIFF', 'TAIL', 'BEACH', 'ROBOT', 'SNOW', 'POINT', 'SCREEN'], 'guessed': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'turn': (<Team.RED: 0>, <Role.SPYMASTER: 0>)}\n",
      "Response: <|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "1\n",
      "PANTS\n",
      "ROW\n",
      "HOTEL\n",
      "FROST\n",
      "CUT\n",
      "CLIFF\n",
      "BEACH\n",
      "SNOW\n",
      "COURT\n",
      "BERMUDA\n",
      "HOLD\n",
      "CUT\n",
      "COURT\n",
      "TR\n",
      "Spymaster's Action: \n",
      "Current Reward: -10\n",
      "Info: {'result': 'Invalid hint: . Game over.', 'error': 'ValueError: Hint must be a single word followed by a count.'}\n",
      "Observation State: {'board': [<Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.ASSASSIN: 3>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.RED: 0>, <Color.RED: 0>, <Color.NEUTRAL: 2>], 'words': ['STRIKE', 'ARM', 'PORT', 'MICROSCOPE', 'SHOP', 'CALF', 'FISH', 'BOARD', 'DUCK', 'BOLT', 'SPELL', 'GROUND', 'JET', 'MOLE', 'CROSS', 'BERMUDA', 'PHOENIX', 'NUT', 'BARK', 'SCHOOL', 'TAP', 'LINK', 'DIAMOND', 'KEY', 'TRIANGLE'], 'guessed': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'turn': (<Team.RED: 0>, <Role.SPYMASTER: 0>)}\n",
      "Response: <|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "1\n",
      "STRIKE\n",
      "PORT\n",
      "SHOP\n",
      "JET\n",
      "CROSS\n",
      "SHELL\n",
      "CUP\n",
      "CUP\n",
      "CUP\n",
      "CUP\n",
      "CUP\n",
      "CUP\n",
      "CUP\n",
      "CUP\n",
      "CUP\n",
      "\n",
      "Spymaster's Action: \n",
      "Current Reward: -10\n",
      "Info: {'result': 'Invalid hint: . Game over.', 'error': 'ValueError: Hint must be a single word followed by a count.'}\n",
      "Observation State: {'board': [<Color.BLUE: 1>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.ASSASSIN: 3>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>], 'words': ['COLD', 'RABBIT', 'SWITCH', 'AMBULANCE', 'NIGHT', 'UNDERTAKER', 'BOOT', 'HOTEL', 'TURKEY', 'BEACH', 'PORT', 'GENIUS', 'CHICK', 'FACE', 'WATER', 'ORGAN', 'JUPITER', 'SHADOW', 'GLASS', 'STOCK', 'KEY', 'SATELLITE', 'SNOW', 'SHOP', 'CHECK'], 'guessed': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'turn': (<Team.RED: 0>, <Role.SPYMASTER: 0>)}\n",
      "Response: <|start_header_id|>assistant<|start_header_id|>\n",
      "\n",
      "1\n",
      "RAB\n",
      "\tB\n",
      "\t|\t\n",
      "\t|\t\n",
      "\t|\t\n",
      "\t|\t\n",
      "\t|\t\n",
      "\t|\t\n",
      "\t|\t\n",
      "\t|\t\n",
      "\t|\t\n",
      "\t|\t\n",
      "\t|\t\n",
      "\t|\t\n",
      "\t|\t\n",
      "\n",
      "Spymaster's Action: \n",
      "Current Reward: -10\n",
      "Info: {'result': 'Invalid hint: . Game over.', 'error': 'ValueError: Hint must be a single word followed by a count.'}\n",
      "Observation State: {'board': [<Color.RED: 0>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.NEUTRAL: 2>, <Color.ASSASSIN: 3>, <Color.NEUTRAL: 2>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.RED: 0>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>], 'words': ['COOK', 'MOUTH', 'BERRY', 'FIRE', 'TEACHER', 'COMPOUND', 'PLATYPUS', 'PANTS', 'RABBIT', 'SCUBA DIVER', 'WAR', 'AFRICA', 'BAR', 'PART', 'HOOK', 'HEART', 'NUT', 'BEAT', 'MARCH', 'DANCE', 'POUND', 'SNOW', 'BOW', 'TOWER', 'CHARGE'], 'guessed': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'turn': (<Team.RED: 0>, <Role.SPYMASTER: 0>)}\n",
      "Response: <|start_header_id|>assistantlis\n",
      "1\n",
      "B\n",
      "I\n",
      "S\n",
      "U\n",
      "(O)\n",
      "(H)\n",
      "(P)\n",
      "(N)\n",
      "(D)\n",
      "(S)\n",
      "(A)\n",
      "(B)\n",
      "(C)\n",
      "(D)\n",
      "(E)\n",
      "(F)\n",
      "(G)\n",
      "(H)\n",
      "(I)\n",
      "(K)\n",
      "(L)\n",
      "(M)\n",
      "\n",
      "Spymaster's Action: \n",
      "Current Reward: -10\n",
      "Info: {'result': 'Invalid hint: . Game over.', 'error': 'ValueError: Hint must be a single word followed by a count.'}\n",
      "Observation State: {'board': [<Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.ASSASSIN: 3>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.RED: 0>], 'words': ['NEEDLE', 'CAST', 'FILM', 'CHEST', 'SPINE', 'PITCH', 'SPIKE', 'SPACE', 'JACK', 'CASINO', 'COMIC', 'GAS', 'ANTARCTICA', 'BAT', 'BARK', 'DISEASE', 'STRING', 'FIRE', 'PYRAMID', 'HIMALAYAS', 'KNIFE', 'REVOLUTION', 'VET', 'TEACHER', 'SERVER'], 'guessed': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'turn': (<Team.RED: 0>, <Role.SPYMASTER: 0>)}\n",
      "Response: <|start_header_id|>assistant/participant/partice\n",
      "\n",
      "1\n",
      "/K\n",
      "/N\n",
      "/P\n",
      "/F\n",
      "\n",
      "2\n",
      "/H\n",
      "/C\n",
      "/K\n",
      "/F\n",
      "/G\n",
      "\n",
      "3\n",
      "/CON\n",
      "/C\n",
      "/K\n",
      "/F\n",
      "/G\n",
      "\n",
      "4\n",
      "/A\n",
      "/C\n",
      "/K\n",
      "\n",
      "Spymaster's Action: \n",
      "Current Reward: -10\n",
      "Info: {'result': 'Invalid hint: . Game over.', 'error': 'ValueError: Hint must be a single word followed by a count.'}\n",
      "Observation State: {'board': [<Color.RED: 0>, <Color.RED: 0>, <Color.RED: 0>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.NEUTRAL: 2>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.RED: 0>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.ASSASSIN: 3>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>], 'words': ['BAT', 'FOREST', 'CONTRACT', 'CLUB', 'ROULETTE', 'GLOVE', 'KID', 'LITTER', 'POUND', 'CHARGE', 'GRACE', 'CASINO', 'OPERA', 'TRIANGLE', 'FACE', 'BEAR', 'HAWK', 'CRICKET', 'PLANE', 'TRAIN', 'BOLT', 'GROUND', 'LONDON', 'HORSE', 'GREEN'], 'guessed': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'turn': (<Team.RED: 0>, <Role.SPYMASTER: 0>)}\n",
      "Response: <|start_header_id|>KANJI/Y/K//G/A//C/A//D//E/F/G/K/I/K/L/M/K/N/A/K/A/C/K/A/C/K/A/C/K/A/C/K/A/C/K/A/C/K/A/C/K/A/C/K/A\n",
      "Spymaster's Action: \n",
      "Current Reward: -10\n",
      "Info: {'result': 'Invalid hint: . Game over.', 'error': 'ValueError: Hint must be a single word followed by a count.'}\n",
      "Observation State: {'board': [<Color.ASSASSIN: 3>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.RED: 0>, <Color.RED: 0>, <Color.RED: 0>, <Color.RED: 0>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.NEUTRAL: 2>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.BLUE: 1>], 'words': ['BILL', 'BOX', 'DEGREE', 'VET', 'DUCK', 'BERMUDA', 'LIGHT', 'ALPS', 'BUTTON', 'LION', 'PUPIL', 'PIT', 'GLOVE', 'MUG', 'PAPER', 'ROUND', 'TICK', 'STRIKE', 'DRILL', 'MEXICO', 'BOW', 'KNIGHT', 'DROP', 'FISH', 'WITCH'], 'guessed': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'turn': (<Team.RED: 0>, <Role.SPYMASTER: 0>)}\n",
      "Response: /gif.LINE/&/|/Y/MM/CADOW/rschein/Y/CARD/Y/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C/C\n",
      "Spymaster's Action: \n",
      "Current Reward: -10\n",
      "Info: {'result': 'Invalid hint: . Game over.', 'error': 'ValueError: Hint must be a single word followed by a count.'}\n",
      "Observation State: {'board': [<Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.ASSASSIN: 3>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.NEUTRAL: 2>, <Color.NEUTRAL: 2>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.RED: 0>, <Color.NEUTRAL: 2>, <Color.BLUE: 1>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.RED: 0>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.RED: 0>, <Color.BLUE: 1>, <Color.RED: 0>], 'words': ['CAP', 'SCHOOL', 'PANTS', 'CLOAK', 'RACKET', 'LUCK', 'SOCK', 'STRING', 'MEXICO', 'PITCH', 'PART', 'STRIKE', 'HOOD', 'PASTE', 'SNOWMAN', 'STICK', 'DICE', 'POOL', 'SHADOW', 'DROP', 'ALPS', 'INDIA', 'TEMPLE', 'VAN', 'HOLE'], 'guessed': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], 'turn': (<Team.RED: 0>, <Role.SPYMASTER: 0>)}\n",
      "Response: шилаmdimarcafdbšlirubafinger манrubafingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfingerfinger\n",
      "Spymaster's Action: \n",
      "Current Reward: -10\n",
      "Info: {'result': 'Invalid hint: . Game over.', 'error': 'ValueError: Hint must be a single word followed by a count.'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcodenames\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodenames\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43magents\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspymaster\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta-llama/Llama-3.2-1B-Instruct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moperative\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdummy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_games\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CodenamesAI/codenames/train.py:104\u001b[0m, in \u001b[0;36mcodenames\u001b[0;34m(agents, board_shape, num_red, num_blue, num_assassin, word_file, allow_human_player, do_train, num_games, save_dir)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInfo:\u001b[39m\u001b[38;5;124m\"\u001b[39m, info)\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m do_train:\n\u001b[0;32m--> 104\u001b[0m             \u001b[43mspymaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspymaster_reward\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(save_dir):\n",
      "File \u001b[0;32m~/CodenamesAI/codenames/agents.py:99\u001b[0m, in \u001b[0;36mAI.step\u001b[0;34m(self, reward)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo query/response tensors to update.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 99\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mppo_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_tensor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse_tensor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# self.ppo_trainer.log_stats(stats, None, reward)\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/codenames_ai/lib/python3.12/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/codenames_ai/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:832\u001b[0m, in \u001b[0;36mPPOTrainer.step\u001b[0;34m(self, queries, responses, scores, response_masks)\u001b[0m\n\u001b[1;32m    823\u001b[0m             model_inputs \u001b[38;5;241m=\u001b[39m {k: mini_batch_dict[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m model_inputs_names}\n\u001b[1;32m    825\u001b[0m             logprobs, logits, vpreds, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatched_forward_pass(\n\u001b[1;32m    826\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    827\u001b[0m                 mini_batch_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueries\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    830\u001b[0m                 return_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    831\u001b[0m             )\n\u001b[0;32m--> 832\u001b[0m             train_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_minibatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmini_batch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmini_batch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvpreds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmini_batch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmasks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmini_batch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madvantages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmini_batch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m             all_stats\u001b[38;5;241m.\u001b[39mappend(train_stats)\n\u001b[1;32m    844\u001b[0m \u001b[38;5;66;03m# typically, early stopping is done at the epoch level\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/codenames_ai/lib/python3.12/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/codenames_ai/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:1102\u001b[0m, in \u001b[0;36mPPOTrainer.train_minibatch\u001b[0;34m(self, old_logprobs, values, logprobs, logits, vpreds, mask, advantages, returns)\u001b[0m\n\u001b[1;32m   1098\u001b[0m loss_p, loss_v, train_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(\n\u001b[1;32m   1099\u001b[0m     old_logprobs, values, logits, vpreds, logprobs, mask, advantages, returns\n\u001b[1;32m   1100\u001b[0m )\n\u001b[1;32m   1101\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_p \u001b[38;5;241m+\u001b[39m loss_v\n\u001b[0;32m-> 1102\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmax_grad_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39msync_gradients:\n",
      "File \u001b[0;32m~/anaconda3/envs/codenames_ai/lib/python3.12/site-packages/accelerate/accelerator.py:2246\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2246\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/codenames_ai/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/codenames_ai/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/codenames_ai/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from codenames import train\n",
    "\n",
    "train.codenames(\n",
    "    agents = {\n",
    "        \"spymaster\": \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "        \"operative\": \"dummy\",\n",
    "    },\n",
    "    num_games = 10,\n",
    "    do_train=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codenames_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
